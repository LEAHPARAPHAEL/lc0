--backend-opts



# Mobile net not optimized
Benchmark batch size 50 with inference average time 1.95075ms - throughput 25631.1 nps.
Benchmark batch size 100 with inference average time 3.45351ms - throughput 28956 nps.
Benchmark batch size 150 with inference average time 5.01951ms - throughput 29883.4 nps.
Benchmark batch size 200 with inference average time 6.65646ms - throughput 30046 nps.


# Residual net 
Benchmark batch size 50 with inference average time 0.92922ms - throughput 53808.6 nps.
Benchmark batch size 100 with inference average time 1.23695ms - throughput 80843.8 nps.
Benchmark batch size 150 with inference average time 1.55236ms - throughput 96627.2 nps.
Benchmark batch size 200 with inference average time 1.86575ms - throughput 107196 nps.

[-0.117737,0.000000],
[0.386719,0.805176],
[0.627930,0.000000],
[-0.090759,0.805176],
[-1.068359,0.805176],
[-0.105957,0.805176],
[0.603027,0.805176],
[-0.404541,0.805176],
[0.810059,0.805176],




Benchmark batch size 1 with inference average time 0.661928ms - throughput 1510.74 nps.
Benchmark batch size 2 with inference average time 0.618888ms - throughput 3231.6 nps.
Benchmark batch size 3 with inference average time 0.632836ms - throughput 4740.56 nps.
Benchmark batch size 4 with inference average time 0.630924ms - throughput 6339.91 nps.
Benchmark batch size 5 with inference average time 0.929333ms - throughput 5380.2 nps.
Benchmark batch size 6 with inference average time 0.703967ms - throughput 8523.13 nps.
Benchmark batch size 7 with inference average time 0.870602ms - throughput 8040.41 nps.
Benchmark batch size 8 with inference average time 0.918922ms - throughput 8705.85 nps.
Benchmark batch size 9 with inference average time 0.764394ms - throughput 11774 nps.
Benchmark batch size 10 with inference average time 0.622756ms - throughput 16057.7 nps.
Benchmark batch size 11 with inference average time 0.659981ms - throughput 16667.1 nps.
Benchmark batch size 12 with inference average time 0.740303ms - throughput 16209.6 nps.
Benchmark batch size 13 with inference average time 0.72438ms - throughput 17946.4 nps.
Benchmark batch size 14 with inference average time 0.774795ms - throughput 18069.3 nps.
Benchmark batch size 15 with inference average time 0.803757ms - throughput 18662.4 nps.
Benchmark batch size 16 with inference average time 0.762936ms - throughput 20971.6 nps.
Benchmark batch size 17 with inference average time 0.898122ms - throughput 18928.4 nps.
Benchmark batch size 18 with inference average time 0.983858ms - throughput 18295.3 nps.
Benchmark batch size 19 with inference average time 0.808864ms - throughput 23489.7 nps.
Benchmark batch size 20 with inference average time 0.718194ms - throughput 27847.6 nps.
Benchmark batch size 21 with inference average time 0.761461ms - throughput 27578.6 nps.
Benchmark batch size 22 with inference average time 0.852196ms - throughput 25815.7 nps.
Benchmark batch size 23 with inference average time 0.790955ms - throughput 29078.8 nps.
Benchmark batch size 24 with inference average time 0.845207ms - throughput 28395.4 nps.
Benchmark batch size 25 with inference average time 0.862539ms - throughput 28984.2 nps.
Benchmark batch size 26 with inference average time 0.835203ms - throughput 31130.2 nps.
Benchmark batch size 27 with inference average time 0.90894ms - throughput 29704.9 nps.
Benchmark batch size 28 with inference average time 0.852077ms - throughput 32860.9 nps.
Benchmark batch size 29 with inference average time 0.846135ms - throughput 34273.5 nps.
Benchmark batch size 30 with inference average time 0.832801ms - throughput 36023 nps.
Benchmark batch size 31 with inference average time 0.842014ms - throughput 36816.5 nps.
Benchmark batch size 32 with inference average time 0.906182ms - throughput 35313 nps.
Benchmark batch size 33 with inference average time 0.876422ms - throughput 37653.1 nps.
Benchmark batch size 34 with inference average time 0.876863ms - throughput 38774.6 nps.
Benchmark batch size 35 with inference average time 0.888286ms - throughput 39401.7 nps.
Benchmark batch size 36 with inference average time 0.911863ms - throughput 39479.6 nps.
Benchmark batch size 37 with inference average time 0.922345ms - throughput 40115.1 nps.
Benchmark batch size 38 with inference average time 0.967469ms - throughput 39277.7 nps.
Benchmark batch size 39 with inference average time 0.980815ms - throughput 39762.9 nps.
Benchmark batch size 40 with inference average time 0.968757ms - throughput 41290 nps.
Benchmark batch size 41 with inference average time 0.981102ms - throughput 41789.7 nps.
Benchmark batch size 42 with inference average time 1.02482ms - throughput 40982.8 nps.
Benchmark batch size 43 with inference average time 1.02139ms - throughput 42099.4 nps.
Benchmark batch size 44 with inference average time 1.03877ms - throughput 42357.7 nps.
Benchmark batch size 45 with inference average time 1.04662ms - throughput 42995.5 nps.
Benchmark batch size 46 with inference average time 1.05439ms - throughput 43627 nps.
Benchmark batch size 47 with inference average time 1.07353ms - throughput 43780.8 nps.
Benchmark batch size 48 with inference average time 1.18942ms - throughput 40355.8 nps.
Benchmark batch size 49 with inference average time 1.17968ms - throughput 41536.6 nps.
Benchmark batch size 50 with inference average time 1.14626ms - throughput 43620.2 nps.
Benchmark batch size 51 with inference average time 1.13622ms - throughput 44885.7 nps.
Benchmark batch size 52 with inference average time 1.15141ms - throughput 45162.2 nps.
Benchmark batch size 53 with inference average time 1.16083ms - throughput 45657.1 nps.
Benchmark batch size 54 with inference average time 1.174ms - throughput 45996.4 nps.
Benchmark batch size 55 with inference average time 1.18493ms - throughput 46416.4 nps.
Benchmark batch size 56 with inference average time 1.20139ms - throughput 46612.6 nps.
Benchmark batch size 57 with inference average time 1.20969ms - throughput 47119.3 nps.
Benchmark batch size 58 with inference average time 1.23264ms - throughput 47053.6 nps.
Benchmark batch size 59 with inference average time 1.23293ms - throughput 47853.4 nps.
Benchmark batch size 60 with inference average time 1.24423ms - throughput 48222.5 nps.
Benchmark batch size 61 with inference average time 1.25386ms - throughput 48649.8 nps.
Benchmark batch size 62 with inference average time 1.26441ms - throughput 49034.8 nps.
Benchmark batch size 63 with inference average time 1.27903ms - throughput 49256.3 nps.
Benchmark batch size 64 with inference average time 1.32474ms - throughput 48311.5 nps.
Benchmark batch size 65 with inference average time 1.34181ms - throughput 48442.1 nps.
Benchmark batch size 66 with inference average time 1.35578ms - throughput 48680.3 nps.
Benchmark batch size 67 with inference average time 1.36594ms - throughput 49050.4 nps.
Benchmark batch size 68 with inference average time 1.38438ms - throughput 49119.4 nps.
Benchmark batch size 69 with inference average time 1.39318ms - throughput 49526.9 nps.
Benchmark batch size 70 with inference average time 1.40326ms - throughput 49883.9 nps.
Benchmark batch size 71 with inference average time 1.42383ms - throughput 49865.5 nps.
Benchmark batch size 72 with inference average time 1.43368ms - throughput 50220.3 nps.
Benchmark batch size 73 with inference average time 1.44509ms - throughput 50515.9 nps.
Benchmark batch size 74 with inference average time 1.4601ms - throughput 50681.4 nps.
Benchmark batch size 75 with inference average time 1.47699ms - throughput 50778.9 nps.
Benchmark batch size 76 with inference average time 1.48797ms - throughput 51076.3 nps.
Benchmark batch size 77 with inference average time 1.5004ms - throughput 51319.5 nps.
Benchmark batch size 78 with inference average time 1.52082ms - throughput 51288 nps.
Benchmark batch size 79 with inference average time 1.53364ms - throughput 51511.3 nps.
Benchmark batch size 80 with inference average time 1.54854ms - throughput 51661.5 nps.
Benchmark batch size 81 with inference average time 1.56911ms - throughput 51621.7 nps.
Benchmark batch size 82 with inference average time 1.5887ms - throughput 51614.5 nps.
Benchmark batch size 83 with inference average time 1.60474ms - throughput 51721.7 nps.
Benchmark batch size 84 with inference average time 1.6187ms - throughput 51893.4 nps.
Benchmark batch size 85 with inference average time 1.64503ms - throughput 51670.9 nps.
Benchmark batch size 86 with inference average time 1.63765ms - throughput 52514.3 nps.
Benchmark batch size 87 with inference average time 1.65412ms - throughput 52596 nps.
Benchmark batch size 88 with inference average time 1.6598ms - throughput 53018.5 nps.
Benchmark batch size 89 with inference average time 1.68239ms - throughput 52900.9 nps.
Benchmark batch size 90 with inference average time 1.70042ms - throughput 52928.3 nps.
Benchmark batch size 91 with inference average time 1.71498ms - throughput 53061.9 nps.
Benchmark batch size 92 with inference average time 1.72607ms - throughput 53300.4 nps.
Benchmark batch size 93 with inference average time 1.7438ms - throughput 53331.7 nps.
Benchmark batch size 94 with inference average time 1.75474ms - throughput 53569.1 nps.
Benchmark batch size 95 with inference average time 1.77578ms - throughput 53497.5 nps.
Benchmark batch size 96 with inference average time 1.79153ms - throughput 53585.5 nps.
Benchmark batch size 97 with inference average time 1.82848ms - throughput 53049.4 nps.
Benchmark batch size 98 with inference average time 1.83898ms - throughput 53290.4 nps.
Benchmark batch size 99 with inference average time 1.84961ms - throughput 53524.7 nps.
Benchmark batch size 100 with inference average time 1.86706ms - throughput 53560.2 nps.
Benchmark batch size 101 with inference average time 1.88143ms - throughput 53682.6 nps.
Benchmark batch size 102 with inference average time 1.89853ms - throughput 53725.9 nps.
Benchmark batch size 103 with inference average time 1.90797ms - throughput 53984.1 nps.
Benchmark batch size 104 with inference average time 1.92199ms - throughput 54110.5 nps.
Benchmark batch size 105 with inference average time 1.94421ms - throughput 54006.4 nps.
Benchmark batch size 106 with inference average time 1.95769ms - throughput 54145.4 nps.
Benchmark batch size 107 with inference average time 1.97182ms - throughput 54264.6 nps.
Benchmark batch size 108 with inference average time 1.98055ms - throughput 54530.2 nps.
Benchmark batch size 109 with inference average time 2.00968ms - throughput 54237.4 nps.
Benchmark batch size 110 with inference average time 2.02359ms - throughput 54358.9 nps.
Benchmark batch size 111 with inference average time 2.03354ms - throughput 54584.6 nps.
Benchmark batch size 112 with inference average time 2.0504ms - throughput 54623.6 nps.
Benchmark batch size 113 with inference average time 2.06045ms - throughput 54842.4 nps.
Benchmark batch size 114 with inference average time 2.07333ms - throughput 54984.1 nps.
Benchmark batch size 115 with inference average time 2.08432ms - throughput 55173.8 nps.
Benchmark batch size 116 with inference average time 2.0988ms - throughput 55269.6 nps.
Benchmark batch size 117 with inference average time 2.10839ms - throughput 55492.7 nps.
Benchmark batch size 118 with inference average time 2.12656ms - throughput 55488.6 nps.
Benchmark batch size 119 with inference average time 2.14234ms - throughput 55546.8 nps.
Benchmark batch size 120 with inference average time 2.15221ms - throughput 55756.7 nps.
Benchmark batch size 121 with inference average time 2.20252ms - throughput 54937.1 nps.
Benchmark batch size 122 with inference average time 2.21227ms - throughput 55146.9 nps.
Benchmark batch size 123 with inference average time 2.22485ms - throughput 55284.5 nps.
Benchmark batch size 124 with inference average time 2.24435ms - throughput 55249.8 nps.
Benchmark batch size 125 with inference average time 2.26048ms - throughput 55298 nps.
Benchmark batch size 126 with inference average time 2.28438ms - throughput 55157.3 nps.
Benchmark batch size 127 with inference average time 2.30047ms - throughput 55206.2 nps.
Benchmark batch size 128 with inference average time 2.31527ms - throughput 55285.2 nps.
Benchmark batch size 129 with inference average time 2.32354ms - throughput 55518.8 nps.
Benchmark batch size 130 with inference average time 2.33201ms - throughput 55745.8 nps.
Benchmark batch size 131 with inference average time 2.3515ms - throughput 55709.1 nps.
Benchmark batch size 132 with inference average time 2.36544ms - throughput 55803.7 nps.
Benchmark batch size 133 with inference average time 2.38117ms - throughput 55854.9 nps.
Benchmark batch size 134 with inference average time 2.39544ms - throughput 55939.5 nps.
Benchmark batch size 135 with inference average time 2.41543ms - throughput 55890.7 nps.
Benchmark batch size 136 with inference average time 2.42082ms - throughput 56179.3 nps.
Benchmark batch size 137 with inference average time 2.44048ms - throughput 56136.6 nps.
Benchmark batch size 138 with inference average time 2.45252ms - throughput 56268.8 nps.
Benchmark batch size 139 with inference average time 2.46175ms - throughput 56463.9 nps.
Benchmark batch size 140 with inference average time 2.47378ms - throughput 56593.5 nps.
Benchmark batch size 141 with inference average time 2.4853ms - throughput 56733.5 nps.
Benchmark batch size 142 with inference average time 2.50109ms - throughput 56775.2 nps.
Benchmark batch size 143 with inference average time 2.51443ms - throughput 56871.8 nps.
Benchmark batch size 144 with inference average time 2.52858ms - throughput 56949 nps.
Benchmark batch size 145 with inference average time 2.55253ms - throughput 56806.4 nps.
Benchmark batch size 146 with inference average time 2.56433ms - throughput 56934.9 nps.
Benchmark batch size 147 with inference average time 2.57984ms - throughput 56980.3 nps.
Benchmark batch size 148 with inference average time 2.5921ms - throughput 57096.6 nps.
Benchmark batch size 149 with inference average time 2.60302ms - throughput 57241.1 nps.
Benchmark batch size 150 with inference average time 2.62012ms - throughput 57249.3 nps.
Benchmark batch size 151 with inference average time 2.63798ms - throughput 57240.9 nps.
Benchmark batch size 152 with inference average time 2.64799ms - throughput 57402.1 nps.
Benchmark batch size 153 with inference average time 2.66212ms - throughput 57472.9 nps.
Benchmark batch size 154 with inference average time 2.67475ms - throughput 57575.6 nps.
Benchmark batch size 155 with inference average time 2.69431ms - throughput 57528.6 nps.
Benchmark batch size 156 with inference average time 2.71058ms - throughput 57552.2 nps.
Benchmark batch size 157 with inference average time 2.7216ms - throughput 57686.6 nps.
Benchmark batch size 158 with inference average time 2.75749ms - throughput 57298.5 nps.
Benchmark batch size 159 with inference average time 2.74575ms - throughput 57907.7 nps.
Benchmark batch size 160 with inference average time 2.8142ms - throughput 56854.6 nps.
Benchmark batch size 161 with inference average time 2.7804ms - throughput 57905.3 nps.
Benchmark batch size 162 with inference average time 2.80391ms - throughput 57776.5 nps.
Benchmark batch size 163 with inference average time 2.80152ms - throughput 58182.7 nps.
Benchmark batch size 164 with inference average time 2.81087ms - throughput 58344.9 nps.
Benchmark batch size 165 with inference average time 2.82498ms - throughput 58407.6 nps.
Benchmark batch size 166 with inference average time 2.83484ms - throughput 58557.1 nps.
Benchmark batch size 167 with inference average time 2.85022ms - throughput 58592 nps.
Benchmark batch size 168 with inference average time 2.8691ms - throughput 58554.9 nps.
Benchmark batch size 169 with inference average time 2.88605ms - throughput 58557.6 nps.
Benchmark batch size 170 with inference average time 2.8953ms - throughput 58715.8 nps.
Benchmark batch size 171 with inference average time 2.91326ms - throughput 58697.1 nps.
Benchmark batch size 172 with inference average time 2.93058ms - throughput 58691.4 nps.
Benchmark batch size 173 with inference average time 2.94178ms - throughput 58807.9 nps.
Benchmark batch size 174 with inference average time 2.96339ms - throughput 58716.6 nps.
Benchmark batch size 175 with inference average time 2.97354ms - throughput 58852.5 nps.
Benchmark batch size 176 with inference average time 2.98981ms - throughput 58866.7 nps.
Benchmark batch size 177 with inference average time 3.00821ms - throughput 58839 nps.
Benchmark batch size 178 with inference average time 3.02721ms - throughput 58799.9 nps.
Benchmark batch size 179 with inference average time 3.04518ms - throughput 58781.4 nps.
Benchmark batch size 180 with inference average time 3.05773ms - throughput 58867.2 nps.
Benchmark batch size 181 with inference average time 3.10978ms - throughput 58203.5 nps.
Benchmark batch size 182 with inference average time 3.12031ms - throughput 58327.5 nps.
Benchmark batch size 183 with inference average time 3.14225ms - throughput 58238.6 nps.
Benchmark batch size 184 with inference average time 3.15921ms - throughput 58242.4 nps.
Benchmark batch size 185 with inference average time 3.17297ms - throughput 58305.1 nps.
Benchmark batch size 186 with inference average time 3.18707ms - throughput 58360.8 nps.
Benchmark batch size 187 with inference average time 3.20347ms - throughput 58374.2 nps.
Benchmark batch size 188 with inference average time 3.21995ms - throughput 58386 nps.
Benchmark batch size 189 with inference average time 3.23773ms - throughput 58374.3 nps.
Benchmark batch size 190 with inference average time 3.25437ms - throughput 58383.1 nps.
Benchmark batch size 191 with inference average time 3.27155ms - throughput 58382.2 nps.
Benchmark batch size 192 with inference average time 3.29451ms - throughput 58278.7 nps.
Benchmark batch size 193 with inference average time 3.32902ms - throughput 57975 nps.
Benchmark batch size 194 with inference average time 3.34493ms - throughput 57998.2 nps.
Benchmark batch size 195 with inference average time 3.36029ms - throughput 58030.7 nps.
Benchmark batch size 196 with inference average time 3.37774ms - throughput 58026.9 nps.
Benchmark batch size 197 with inference average time 3.39315ms - throughput 58058.1 nps.
Benchmark batch size 198 with inference average time 3.41244ms - throughput 58022.9 nps.
Benchmark batch size 199 with inference average time 3.42695ms - throughput 58069.2 nps.
Benchmark batch size 200 with inference average time 3.44454ms - throughput 58062.9 nps.
Benchmark batch size 201 with inference average time 3.45805ms - throughput 58125.3 nps.
Benchmark batch size 202 with inference average time 3.47803ms - throughput 58078.9 nps.
Benchmark batch size 203 with inference average time 3.49655ms - throughput 58057.2 nps.
Benchmark batch size 204 with inference average time 3.53024ms - throughput 57786.4 nps.
Benchmark batch size 205 with inference average time 3.54374ms - throughput 57848.5 nps.
Benchmark batch size 206 with inference average time 3.5671ms - throughput 57750 nps.
Benchmark batch size 207 with inference average time 3.58498ms - throughput 57740.9 nps.
Benchmark batch size 208 with inference average time 3.61962ms - throughput 57464.6 nps.
Benchmark batch size 209 with inference average time 3.59477ms - throughput 58140 nps.
Benchmark batch size 210 with inference average time 3.60955ms - throughput 58179 nps.
Benchmark batch size 211 with inference average time 3.63813ms - throughput 57996.9 nps.
Benchmark batch size 212 with inference average time 3.64081ms - throughput 58228.8 nps.
Benchmark batch size 213 with inference average time 3.67001ms - throughput 58038 nps.
Benchmark batch size 214 with inference average time 3.69375ms - throughput 57935.6 nps.


Benchmark batch size 1 with inference average time 0.572502ms - throughput 1746.72 nps.
Benchmark batch size 2 with inference average time 0.566157ms - throughput 3532.59 nps.
Benchmark batch size 3 with inference average time 0.572894ms - throughput 5236.57 nps.
Benchmark batch size 4 with inference average time 0.569457ms - throughput 7024.24 nps.
Benchmark batch size 5 with inference average time 0.578826ms - throughput 8638.17 nps.
Benchmark batch size 6 with inference average time 0.570501ms - throughput 10517.1 nps.
Benchmark batch size 7 with inference average time 0.571406ms - throughput 12250.5 nps.
Benchmark batch size 8 with inference average time 0.600578ms - throughput 13320.5 nps.
Benchmark batch size 9 with inference average time 0.567535ms - throughput 15858.1 nps.
Benchmark batch size 10 with inference average time 0.573805ms - throughput 17427.5 nps.
Benchmark batch size 11 with inference average time 0.578511ms - throughput 19014.3 nps.
Benchmark batch size 12 with inference average time 0.574611ms - throughput 20883.7 nps.
Benchmark batch size 13 with inference average time 0.569765ms - throughput 22816.4 nps.
Benchmark batch size 14 with inference average time 0.579366ms - throughput 24164.3 nps.
Benchmark batch size 15 with inference average time 0.616272ms - throughput 24339.9 nps.
Benchmark batch size 16 with inference average time 0.60292ms - throughput 26537.5 nps.
Benchmark batch size 17 with inference average time 0.676245ms - throughput 25138.8 nps.
Benchmark batch size 18 with inference average time 0.631678ms - throughput 28495.5 nps.
Benchmark batch size 19 with inference average time 0.644682ms - throughput 29471.9 nps.
Benchmark batch size 20 with inference average time 0.650245ms - throughput 30757.6 nps.
Benchmark batch size 21 with inference average time 0.660135ms - throughput 31811.7 nps.
Benchmark batch size 22 with inference average time 0.671824ms - throughput 32746.7 nps.
Benchmark batch size 23 with inference average time 0.682853ms - throughput 33682.2 nps.
Benchmark batch size 24 with inference average time 0.692978ms - throughput 34633.1 nps.
Benchmark batch size 25 with inference average time 0.758079ms - throughput 32978.1 nps.
Benchmark batch size 26 with inference average time 0.762892ms - throughput 34080.8 nps.
Benchmark batch size 27 with inference average time 0.77928ms - throughput 34647.4 nps.
Benchmark batch size 28 with inference average time 0.789529ms - throughput 35464.2 nps.
Benchmark batch size 29 with inference average time 0.801601ms - throughput 36177.6 nps.
Benchmark batch size 30 with inference average time 0.811563ms - throughput 36965.7 nps.
Benchmark batch size 31 with inference average time 0.823945ms - throughput 37623.9 nps.
Benchmark batch size 32 with inference average time 0.88722ms - throughput 36067.7 nps.
Benchmark batch size 33 with inference average time 0.850599ms - throughput 38796.2 nps.
Benchmark batch size 34 with inference average time 0.86459ms - throughput 39325 nps.
Benchmark batch size 35 with inference average time 0.874801ms - throughput 40009.1 nps.
Benchmark batch size 36 with inference average time 0.887369ms - throughput 40569.4 nps.
Benchmark batch size 37 with inference average time 0.9001ms - throughput 41106.5 nps.
Benchmark batch size 38 with inference average time 0.9138ms - throughput 41584.6 nps.
Benchmark batch size 39 with inference average time 0.924416ms - throughput 42188.8 nps.
Benchmark batch size 40 with inference average time 0.937849ms - throughput 42650.8 nps.
Benchmark batch size 41 with inference average time 0.953385ms - throughput 43004.7 nps.
Benchmark batch size 42 with inference average time 0.963924ms - throughput 43571.9 nps.
Benchmark batch size 43 with inference average time 0.976487ms - throughput 44035.4 nps.
Benchmark batch size 44 with inference average time 0.989357ms - throughput 44473.3 nps.
Benchmark batch size 45 with inference average time 0.999456ms - throughput 45024.5 nps.
Benchmark batch size 46 with inference average time 1.01193ms - throughput 45457.6 nps.
Benchmark batch size 47 with inference average time 1.02576ms - throughput 45819.8 nps.
Benchmark batch size 48 with inference average time 1.03191ms - throughput 46515.5 nps.
Benchmark batch size 49 with inference average time 1.09637ms - throughput 44693 nps.
Benchmark batch size 50 with inference average time 1.11099ms - throughput 45004.8 nps.
Benchmark batch size 51 with inference average time 1.12803ms - throughput 45211.5 nps.
Benchmark batch size 52 with inference average time 1.14454ms - throughput 45433 nps.
Benchmark batch size 53 with inference average time 1.15178ms - throughput 46015.8 nps.
Benchmark batch size 54 with inference average time 1.17197ms - throughput 46076.4 nps.
Benchmark batch size 55 with inference average time 1.18499ms - throughput 46414.1 nps.
Benchmark batch size 56 with inference average time 1.19594ms - throughput 46825 nps.
Benchmark batch size 57 with inference average time 1.20475ms - throughput 47312.6 nps.
Benchmark batch size 58 with inference average time 1.21407ms - throughput 47773.2 nps.
Benchmark batch size 59 with inference average time 1.22523ms - throughput 48154.1 nps.
Benchmark batch size 60 with inference average time 1.23915ms - throughput 48420.3 nps.
Benchmark batch size 61 with inference average time 1.25099ms - throughput 48761.4 nps.
Benchmark batch size 62 with inference average time 1.26916ms - throughput 48851.3 nps.
Benchmark batch size 63 with inference average time 1.27735ms - throughput 49320.8 nps.
Benchmark batch size 64 with inference average time 1.32382ms - throughput 48345.1 nps.
Benchmark batch size 65 with inference average time 1.33526ms - throughput 48679.7 nps.
Benchmark batch size 66 with inference average time 1.35167ms - throughput 48828.4 nps.
Benchmark batch size 67 with inference average time 1.36815ms - throughput 48971.3 nps.
Benchmark batch size 68 with inference average time 1.38084ms - throughput 49245.5 nps.
Benchmark batch size 69 with inference average time 1.39785ms - throughput 49361.4 nps.
Benchmark batch size 70 with inference average time 1.41105ms - throughput 49608.4 nps.
Benchmark batch size 71 with inference average time 1.42548ms - throughput 49807.7 nps.
Benchmark batch size 72 with inference average time 1.44121ms - throughput 49958.1 nps.
Benchmark batch size 73 with inference average time 1.45063ms - throughput 50323.1 nps.
Benchmark batch size 74 with inference average time 1.46077ms - throughput 50658.1 nps.
Benchmark batch size 75 with inference average time 1.4767ms - throughput 50789.1 nps.
Benchmark batch size 76 with inference average time 1.49243ms - throughput 50923.7 nps.
Benchmark batch size 77 with inference average time 1.50431ms - throughput 51186.4 nps.
Benchmark batch size 78 with inference average time 1.5185ms - throughput 51366.4 nps.
Benchmark batch size 79 with inference average time 1.53402ms - throughput 51498.6 nps.
Benchmark batch size 80 with inference average time 1.55382ms - throughput 51486.1 nps.
Benchmark batch size 81 with inference average time 1.57211ms - throughput 51522.9 nps.
Benchmark batch size 82 with inference average time 1.5851ms - throughput 51731.8 nps.
Benchmark batch size 83 with inference average time 1.59878ms - throughput 51914.5 nps.
Benchmark batch size 84 with inference average time 1.61467ms - throughput 52023 nps.
Benchmark batch size 85 with inference average time 1.62522ms - throughput 52300.8 nps.
Benchmark batch size 86 with inference average time 1.63963ms - throughput 52451 nps.
Benchmark batch size 87 with inference average time 1.65073ms - throughput 52703.9 nps.
Benchmark batch size 88 with inference average time 1.66287ms - throughput 52920.6 nps.
Benchmark batch size 89 with inference average time 1.67895ms - throughput 53009.3 nps.
Benchmark batch size 90 with inference average time 1.69266ms - throughput 53170.9 nps.
Benchmark batch size 91 with inference average time 1.70967ms - throughput 53226.7 nps.
Benchmark batch size 92 with inference average time 1.72836ms - throughput 53229.6 nps.
Benchmark batch size 93 with inference average time 1.74078ms - throughput 53424.2 nps.
Benchmark batch size 94 with inference average time 1.75591ms - throughput 53533.6 nps.
Benchmark batch size 95 with inference average time 1.77177ms - throughput 53618.5 nps.
Benchmark batch size 96 with inference average time 1.80102ms - throughput 53303.3 nps.
Benchmark batch size 97 with inference average time 1.83605ms - throughput 52830.8 nps.
Benchmark batch size 98 with inference average time 1.84832ms - throughput 53021.2 nps.
Benchmark batch size 99 with inference average time 1.85909ms - throughput 53252 nps.
Benchmark batch size 100 with inference average time 1.87191ms - throughput 53421.5 nps.
Benchmark batch size 101 with inference average time 1.88302ms - throughput 53637.2 nps.
Benchmark batch size 102 with inference average time 1.89599ms - throughput 53797.9 nps.
Benchmark batch size 103 with inference average time 1.90979ms - throughput 53932.7 nps.
Benchmark batch size 104 with inference average time 1.9311ms - throughput 53855.2 nps.
Benchmark batch size 105 with inference average time 1.94286ms - throughput 54044.1 nps.
Benchmark batch size 106 with inference average time 1.96185ms - throughput 54030.7 nps.
Benchmark batch size 107 with inference average time 1.9799ms - throughput 54043.1 nps.
Benchmark batch size 108 with inference average time 1.99467ms - throughput 54144.2 nps.
Benchmark batch size 109 with inference average time 2.01717ms - throughput 54036 nps.
Benchmark batch size 110 with inference average time 2.03433ms - throughput 54072 nps.
Benchmark batch size 111 with inference average time 2.04939ms - throughput 54162.6 nps.
Benchmark batch size 112 with inference average time 2.06004ms - throughput 54367.9 nps.
Benchmark batch size 113 with inference average time 2.07517ms - throughput 54453.5 nps.
Benchmark batch size 114 with inference average time 2.08349ms - throughput 54715.8 nps.
Benchmark batch size 115 with inference average time 2.09549ms - throughput 54879.7 nps.
Benchmark batch size 116 with inference average time 2.10873ms - throughput 55009.4 nps.
Benchmark batch size 117 with inference average time 2.12124ms - throughput 55156.5 nps.
Benchmark batch size 118 with inference average time 2.13318ms - throughput 55316.6 nps.
Benchmark batch size 119 with inference average time 2.14427ms - throughput 55496.8 nps.
Benchmark batch size 120 with inference average time 2.15798ms - throughput 55607.6 nps.
Benchmark batch size 121 with inference average time 2.21721ms - throughput 54573 nps.
Benchmark batch size 122 with inference average time 2.23145ms - throughput 54673 nps.
Benchmark batch size 123 with inference average time 2.24404ms - throughput 54812 nps.
Benchmark batch size 124 with inference average time 2.25345ms - throughput 55026.6 nps.
Benchmark batch size 125 with inference average time 2.26911ms - throughput 55087.6 nps.
Benchmark batch size 126 with inference average time 2.28251ms - throughput 55202.3 nps.
Benchmark batch size 127 with inference average time 2.29481ms - throughput 55342.2 nps.
Benchmark batch size 128 with inference average time 2.30793ms - throughput 55461 nps.
Benchmark batch size 129 with inference average time 2.31812ms - throughput 55648.7 nps.
Benchmark batch size 130 with inference average time 2.34057ms - throughput 55542.1 nps.
Benchmark batch size 131 with inference average time 2.34504ms - throughput 55862.7 nps.
Benchmark batch size 132 with inference average time 2.36034ms - throughput 55924.1 nps.
Benchmark batch size 133 with inference average time 2.37844ms - throughput 55919 nps.
Benchmark batch size 134 with inference average time 2.39234ms - throughput 56012.1 nps.
Benchmark batch size 135 with inference average time 2.413ms - throughput 55946.9 nps.
Benchmark batch size 136 with inference average time 2.42561ms - throughput 56068.4 nps.
Benchmark batch size 137 with inference average time 2.44175ms - throughput 56107.3 nps.
Benchmark batch size 138 with inference average time 2.45563ms - throughput 56197.4 nps.
Benchmark batch size 139 with inference average time 2.4728ms - throughput 56211.5 nps.
Benchmark batch size 140 with inference average time 2.48684ms - throughput 56296.3 nps.
Benchmark batch size 141 with inference average time 2.49994ms - throughput 56401.3 nps.
Benchmark batch size 142 with inference average time 2.50659ms - throughput 56650.6 nps.
Benchmark batch size 143 with inference average time 2.5155ms - throughput 56847.5 nps.
Benchmark batch size 144 with inference average time 2.53005ms - throughput 56915.8 nps.
Benchmark batch size 145 with inference average time 2.55893ms - throughput 56664.4 nps.
Benchmark batch size 146 with inference average time 2.56951ms - throughput 56820.1 nps.
Benchmark batch size 147 with inference average time 2.58208ms - throughput 56930.9 nps.
Benchmark batch size 148 with inference average time 2.59817ms - throughput 56963.2 nps.
Benchmark batch size 149 with inference average time 2.61027ms - throughput 57082.3 nps.
Benchmark batch size 150 with inference average time 2.62419ms - throughput 57160.4 nps.
Benchmark batch size 151 with inference average time 2.6374ms - throughput 57253.3 nps.
Benchmark batch size 152 with inference average time 2.64823ms - throughput 57396.9 nps.
Benchmark batch size 153 with inference average time 2.66608ms - throughput 57387.6 nps.
Benchmark batch size 154 with inference average time 2.66781ms - throughput 57725.2 nps.
Benchmark batch size 155 with inference average time 2.68317ms - throughput 57767.4 nps.
Benchmark batch size 156 with inference average time 2.69572ms - throughput 57869.5 nps.
Benchmark batch size 157 with inference average time 2.71187ms - throughput 57893.5 nps.
Benchmark batch size 158 with inference average time 2.72812ms - throughput 57915.3 nps.
Benchmark batch size 159 with inference average time 2.74646ms - throughput 57892.8 nps.
Benchmark batch size 160 with inference average time 3.01565ms - throughput 53056.6 nps.
Benchmark batch size 161 with inference average time 3.1604ms - throughput 50942.9 nps.
Benchmark batch size 162 with inference average time 2.97306ms - throughput 54489.3 nps.
Benchmark batch size 163 with inference average time 2.8074ms - throughput 58060.9 nps.
Benchmark batch size 164 with inference average time 2.81923ms - throughput 58172 nps.
Benchmark batch size 165 with inference average time 2.83276ms - throughput 58247 nps.
Benchmark batch size 166 with inference average time 2.84872ms - throughput 58271.8 nps.
Benchmark batch size 167 with inference average time 2.86775ms - throughput 58233.7 nps.
Benchmark batch size 168 with inference average time 2.87731ms - throughput 58387.8 nps.
Benchmark batch size 169 with inference average time 2.89114ms - throughput 58454.5 nps.
Benchmark batch size 170 with inference average time 2.9104ms - throughput 58411.3 nps.
Benchmark batch size 171 with inference average time 2.91511ms - throughput 58659.9 nps.
Benchmark batch size 172 with inference average time 2.94411ms - throughput 58421.7 nps.
Benchmark batch size 173 with inference average time 2.95174ms - throughput 58609.5 nps.
Benchmark batch size 174 with inference average time 2.96174ms - throughput 58749.2 nps.
Benchmark batch size 175 with inference average time 2.97699ms - throughput 58784.3 nps.
Benchmark batch size 176 with inference average time 2.99308ms - throughput 58802.2 nps.
Benchmark batch size 177 with inference average time 3.00285ms - throughput 58944.1 nps.
Benchmark batch size 178 with inference average time 3.02122ms - throughput 58916.6 nps.
Benchmark batch size 179 with inference average time 3.04523ms - throughput 58780.4 nps.
Benchmark batch size 180 with inference average time 3.05228ms - throughput 58972.2 nps.
Benchmark batch size 181 with inference average time 3.1074ms - throughput 58248.1 nps.
Benchmark batch size 182 with inference average time 3.13099ms - throughput 58128.5 nps.
Benchmark batch size 183 with inference average time 3.14576ms - throughput 58173.6 nps.
Benchmark batch size 184 with inference average time 3.14899ms - throughput 58431.5 nps.
Benchmark batch size 185 with inference average time 3.17429ms - throughput 58280.8 nps.
Benchmark batch size 186 with inference average time 3.19ms - throughput 58307.2 nps.
Benchmark batch size 187 with inference average time 3.19876ms - throughput 58460.2 nps.
Benchmark batch size 188 with inference average time 3.22131ms - throughput 58361.3 nps.
Benchmark batch size 189 with inference average time 3.23919ms - throughput 58348 nps.
Benchmark batch size 190 with inference average time 3.25752ms - throughput 58326.6 nps.
Benchmark batch size 191 with inference average time 3.26747ms - throughput 58455 nps.
Benchmark batch size 192 with inference average time 3.29547ms - throughput 58261.8 nps.
Benchmark batch size 193 with inference average time 3.32636ms - throughput 58021.5 nps.
Benchmark batch size 194 with inference average time 3.33657ms - throughput 58143.6 nps.
Benchmark batch size 195 with inference average time 3.35348ms - throughput 58148.6 nps.
Benchmark batch size 196 with inference average time 3.3734ms - throughput 58101.6 nps.
Benchmark batch size 197 with inference average time 3.39539ms - throughput 58019.8 nps.
Benchmark batch size 198 with inference average time 3.40692ms - throughput 58117.1 nps.
Benchmark batch size 199 with inference average time 3.42661ms - throughput 58074.8 nps.
Benchmark batch size 200 with inference average time 3.44102ms - throughput 58122.3 nps.
Benchmark batch size 201 with inference average time 3.45385ms - throughput 58195.9 nps.
Benchmark batch size 202 with inference average time 3.47728ms - throughput 58091.5 nps.
Benchmark batch size 203 with inference average time 3.50022ms - throughput 57996.3 nps.
Benchmark batch size 204 with inference average time 3.50166ms - throughput 58258.1 nps.
Benchmark batch size 205 with inference average time 3.52088ms - throughput 58224 nps.
Benchmark batch size 206 with inference average time 3.54775ms - throughput 58065 nps.
Benchmark batch size 207 with inference average time 3.55931ms - throughput 58157.3 nps.
Benchmark batch size 208 with inference average time 3.58057ms - throughput 58091.3 nps.
Benchmark batch size 209 with inference average time 3.62041ms - throughput 57728.3 nps.
Benchmark batch size 210 with inference average time 3.61417ms - throughput 58104.6 nps.
Benchmark batch size 211 with inference average time 3.81794ms - throughput 55265.3 nps.